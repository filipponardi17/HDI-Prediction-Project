---
title: "HW2_Filippo_Nardi"
author: "Filippo Nardi"
date: "2023-12-11"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This work is highly correlated to my first homework in this course. I will once again use the World Value survey to asses the differents social and life values based on the HDI index provided by the United Nations.

First let's import all the librarries needed for this project

```{r}
library(randomForest)
library(shapper)
library(GGally)
library(ggplot2)
library(mice)
library(VIM)
library(caret)
library(tidyr) 
library(factoextra)
library(cluster)
library(mclust)
library(kernlab)
library(mice)

```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}

```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

Here I will load the data, W7R (Wave 7 Reduced) is an already filtered version of the EVS_WVS_joint2, I will use this is as it's focused on readibilty (columns renamed) and social attitudes.

Data2 in non other than the dataset containing the Human Development Index (HDI) produced by the United Nations Development Programme, it has other columnso other than HDI but for this analysis it's the thing I value the most.

```{r}
data = load("W7R.rds")
data2 =  read.csv("human-development-index-hdi-2014.csv", header = TRUE, stringsAsFactors = FALSE, fileEncoding = "UTF-8")

#names(W7R)


```

Since both datasets have differents standard for the names of the countries this list is for unifying that.

```{r}

rename_mapping <- c(
  "Bolivia (Plurinational State of)" = "Bolivia",
  "Bosnia and Herzegovina" = "Bosnia",
  "Czech Republic" = "Czechia",
  "Hong Kong, China (SAR)" = "HongKong-SAR",
  "Iran (Islamic Republic of)" = "Iran",
  "Korea (Republic of)" = "South-Korea",
  "New Zealand" = "New-Zealand",
  "Russian Federation" = "Russia",
  "Viet Nam" = "Vietnam",
  "The former Yugoslav Republic of Macedonia" = "North-Macedonia",
  "United Kingdom" = "Great-Britain",
  "United States" = "United-States"
)

data2$Location <- ifelse(data2$Location %in% names(rename_mapping), rename_mapping[data2$Location], data2$Location)


```

This is part is for creating the column in HDI in W7R and then appending the correct HDI value from the United Nations dataset

```{r}
W7R$HDI <- NA

for (i in 1:nrow(W7R)) {
  country <- W7R$cntry_name[i]
  
  match_rows <- which(data2$Location == country)
  
  if (length(match_rows) > 0) {
    W7R$HDI[i] <- data2$Human.Development.Index..HDI.[match_rows[1]]
  }
}


# Check the updated W7R with the new 'HDI' column
print(unique(W7R$HDI))
```

Here we will simply check and drop out from the analysis those countries that from W7R don't have their HDI listed.

Those countries are the results of unique_countries_with_NA_HDI and are "Taiwan", "Ethiopia", "Macau" and "PuertoRico".

```{r}
rows_with_NA <- which(is.na(W7R$HDI))

# Extract corresponding country names for rows with NA HDI
countries_with_NA_HDI <- W7R$cntry_name[rows_with_NA]

# Show unique country names with NA HDI
unique_countries_with_NA_HDI <- unique(countries_with_NA_HDI)
unique_countries_with_NA_HDI

# Filter out rows in W7R that correspond to unique_countries_with_NA_HDI
W7R <- W7R[!(W7R$cntry_name %in% unique_countries_with_NA_HDI), ]

# Reset row names after filtering
rownames(W7R) <- NULL

```

Let's have a preliminary summary of the Dataset.

So since the 3 biggest indicators for HDI is education, expected life and GNI per capita i have to drop some variables that would just be too highly correlated with HDI, those are income level and education level. I will also drop the column "E181_EVS5" that is what party the person has voted for as a binary classification in populist and non populist like the last homework would work but finding obscure parties in third world countries is a hassle that I don't want to take

We can clearly see we have a lot NAs

```{r}
names(W7R)
dim(W7R)
str(W7R)
summary(W7R)

W7R <- W7R[, !(names(W7R) %in% c("incm_lvl", "edu_lvl", "E181_EVS5"))]

na_count <- colSums(is.na(W7R))
print(na_count)
na_count2 <- sum(is.na(W7R$HDI))
print(na_count2)

```

```{r}
# Calculate correlations
correlation_matrix <- cor(W7R)

# Create a function to filter significant correlations
significant_correlations <- function(correlation_matrix, threshold = 0.05) {
  sig_corr <- cor.test(correlation_matrix, method = "pearson")
  sig_corr$p.value < threshold
}

# Apply the function to the correlation matrix
significant_corr <- apply(correlation_matrix, 1, significant_correlations)

# Print significant correlations
for (i in 1:nrow(correlation_matrix)) {
  for (j in 1:ncol(correlation_matrix)) {
    if (significant_corr[i, j] && i != j) {
      cat(names(correlation_matrix)[i], "and", names(correlation_matrix)[j], ":", correlation_matrix[i, j], "\n")
    }
  }
}
```

```{r}
names(W7R)
```

```{r}

#md.pattern(W7R)



#LET'S IMPUTE THE NAs
imputed_W7R <- mice(W7R, m = 5, maxit = 5, method = "pmm", seed = 123)

complete_W7R <- complete(imputed_W7R)

save(complete_W7R, file= "complete_W7R.rda")
#load("complete_W7R.rda")


#remove dupes 

#imputed_data <- complete_W7R[!duplicated(complete_W7R), ]


#let's make sure we have no NAs

#na_count <- colSums(is.na(imputed_data))
#print(na_count)
```

# Feature selection

```{r}


#basically all of this code it's just to exclude pop_vote from scaling
numeric_vars_to_scale <- sapply(pigs, is.numeric)

numeric_vars_to_scale["pop_vote"] <- FALSE

scaled_df <- pigs

scaled_df[, numeric_vars_to_scale] <- scale(scaled_df[, numeric_vars_to_scale])


# I will be using Random Forest feature importance to obtain the first 20 variables to predict pop_vote scaled and not scaled:

#NOT SCALED 

set.seed(123)

pop_rf = randomForest(pop_vote ~ ., data=pigs, na.action = na.roughfix,
                               proximity = T,
                               ntree=500, mtry=4, importance=TRUE)




```

# Splitting

cambia nomi dataset!!!

```{r}
in_train <- createDataPartition(log(W7R$HDI), p = 0.75, list = FALSE)  # 75% for training
training <- W7R[ in_train,]
testing <- W7R[-in_train,]
nrow(training)
nrow(testing)

```

```{r}
training %>% ggplot(aes(x=HDI)) + geom_density(fill="navyblue") #+ scale_x_log10()
```

```{r}

training %>% ggplot(aes(x=log(c_eu1), y=log(HDI))) + geom_point(color = "navyblue")
```

```{r}
names(training)
```

```{r}

library(ggplot2)
library(GGally)

ggcorr(training, label = TRUE)
```

# Regression

```{r}

linFit <- lm(log(HDI) ~ sqft, data=training)
linFit
```
